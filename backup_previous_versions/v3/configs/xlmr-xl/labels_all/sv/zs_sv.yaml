data:
  train: en-fi-fr-tr
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 8
peft:
  enable: True
dataloader:
  train_batch_size: 1
  balancing_sampler: True
# 42 {'f1': 0.7509765072176621, 'f1_th05': 0.7363443552032266, 'precision': 0.7305066079295154, 'recall': 0.772626674432149, 'pr_auc': 0.8288466272004139, 'roc_auc': 0.8748839205974132, 'accuracy': 0.5480686076679159, 'threshold': 0.5499999999999999}
# 43 {'f1': 0.7443730507646639, 'f1_th05': 0.7309241094475993, 'precision': 0.722228298516169, 'recall': 0.7679187502422762, 'pr_auc': 0.8202659193334223, 'roc_auc': 0.872095580637748, 'accuracy': 0.5515278178149322, 'threshold': 0.5499999999999999}
# 44 {'f1': 0.7505011565150347, 'f1_th05': 0.7429894062138341, 'precision': 0.7457860864235366, 'recall': 0.755276225946617, 'pr_auc': 0.8265485040480746, 'roc_auc': 0.8673056557293778, 'accuracy': 0.5574373018160853, 'threshold': 0.5499999999999999}
