data:
  train: fr
  labels: upper
model:
  name: xlm-roberta-large
trainer:
  learning_rate: 3e-5
#=42 {'f1': 0.7427631578947368, 'f1_th05': 0.7230861244019139, 'precision': 0.7181933842239185, 'recall': 0.7690735694822888, 'pr_auc': 0.8284288811542228, 'roc_auc': 0.8617040870811093, 'accuracy': 0.5705076551168412, 'threshold': 0.5499999999999999}
#=43 {'f1': 0.7585492227979275, 'f1_th05': 0.7581993569131833, 'precision': 0.7694463910301331, 'recall': 0.7479564032697548, 'pr_auc': 0.8369312616097094, 'roc_auc': 0.857021186894129, 'accuracy': 0.6172441579371475, 'threshold': 0.5499999999999999}
#=44 {'f1': 0.7572948849982836, 'f1_th05': 0.7536507936507937, 'precision': 0.7633217993079585, 'recall': 0.7513623978201635, 'pr_auc': 0.8402561188417339, 'roc_auc': 0.8580541501522216, 'accuracy': 0.6011281224818694, 'threshold': 0.5499999999999999}

#m42 {'f1': 0.7843005702784301, 'f1_th05': 0.773926868044515, 'precision': 0.7726371447455387, 'recall': 0.7963215258855586, 'pr_auc': 0.8694722236154534, 'roc_auc': 0.8804306320284405, 'accuracy': 0.6406124093473006, 'threshold': 0.5499999999999999}
#m43 {'f1': 0.7778149014366855, 'f1_th05': 0.7578365089121082, 'precision': 0.7632786885245901, 'recall': 0.7929155313351499, 'pr_auc': 0.864248410272501, 'roc_auc': 0.8778514364231672, 'accuracy': 0.6236905721192587, 'threshold': 0.5499999999999999}
#m44 {'f1': 0.7719532554257095, 'f1_th05': 0.755968992248062, 'precision': 0.7570399476096922, 'recall': 0.7874659400544959, 'pr_auc': 0.8615904913513757, 'roc_auc': 0.8746112300004467, 'accuracy': 0.6196615632554392, 'threshold': 0.5499999999999999}

#z42
#z43
#z44
