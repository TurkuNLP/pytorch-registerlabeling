data:
  train: en
  labels: upper
model:
  name: xlm-roberta-large
trainer:
  learning_rate: 3e-5
#=42 {'f1': 0.7577534879587666, 'f1_th05': 0.7458319712324288, 'precision': 0.726505921445003, 'recall': 0.7918098244962392, 'pr_auc': 0.8467260914878847, 'roc_auc': 0.8746048803976046, 'accuracy': 0.604347371721183, 'threshold': 0.5499999999999999}
#=43 {'f1': 0.7587179826301635, 'f1_th05': 0.7477752041935877, 'precision': 0.7222595266073527, 'recall': 0.7990528368465039, 'pr_auc': 0.8502814856754617, 'roc_auc': 0.8775694697025809, 'accuracy': 0.6027798098024872, 'threshold': 0.5499999999999999}
#=44 {'f1': 0.7608216521202504, 'f1_th05': 0.7503767360404023, 'precision': 0.7241755475371319, 'recall': 0.8013743151638963, 'pr_auc': 0.8506637542226831, 'roc_auc': 0.8788761903879785, 'accuracy': 0.6036158428257916, 'threshold': 0.5499999999999999}

#m42 {'f1': 0.7371440991088893, 'f1_th05': 0.723341796255157, 'precision': 0.6929552141222621, 'recall': 0.7873525861268456, 'pr_auc': 0.8202359821423856, 'roc_auc': 0.8687466296171971, 'accuracy': 0.5717420838123106, 'threshold': 0.5499999999999999}
#m43 {'f1': 0.7285733567283034, 'f1_th05': 0.7186765063660694, 'precision': 0.7066678303368825, 'recall': 0.7518803974370879, 'pr_auc': 0.8092081718352588, 'roc_auc': 0.8536382027529426, 'accuracy': 0.582506008987355, 'threshold': 0.5499999999999999}
#m44 {'f1': 0.7302244600254105, 'f1_th05': 0.7102789335799045, 'precision': 0.7402213318069071, 'recall': 0.7204940105859411, 'pr_auc': 0.8151909046183913, 'roc_auc': 0.8421784736017082, 'accuracy': 0.6001672066046608, 'threshold': 0.5999999999999999}

#z42
#z43
#z44
