data:
  train: en
  labels: upper
model:
  name: xlm-roberta-large
trainer:
  learning_rate: 3e-5
#=42 {'f1': 0.7577534879587666, 'f1_th05': 0.7458319712324288, 'precision': 0.726505921445003, 'recall': 0.7918098244962392, 'pr_auc': 0.8467260914878847, 'roc_auc': 0.8746048803976046, 'accuracy': 0.604347371721183, 'threshold': 0.5499999999999999}
#=43 {'f1': 0.7587179826301635, 'f1_th05': 0.7477752041935877, 'precision': 0.7222595266073527, 'recall': 0.7990528368465039, 'pr_auc': 0.8502814856754617, 'roc_auc': 0.8775694697025809, 'accuracy': 0.6027798098024872, 'threshold': 0.5499999999999999}
#=44 {'f1': 0.7608216521202504, 'f1_th05': 0.7503767360404023, 'precision': 0.7241755475371319, 'recall': 0.8013743151638963, 'pr_auc': 0.8506637542226831, 'roc_auc': 0.8788761903879785, 'accuracy': 0.6036158428257916, 'threshold': 0.5499999999999999}
