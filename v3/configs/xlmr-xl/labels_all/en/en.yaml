data:
  train: en
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 4
  best_model_metric: eval_f1
peft:
  enable: True
dataloader:
  train_batch_size: 2
#=42 {'f1': 0.736748974503338, 'f1_th05': 0.7266265852055594, 'precision': 0.7222835514903012, 'recall': 0.7518056467498359, 'pr_auc': 0.8208567587426514, 'roc_auc': 0.863947575783845, 'accuracy': 0.5111296896227401, 'threshold': 0.5499999999999999}
#=43 {'f1': 0.7360691623486381, 'f1_th05': 0.7178885079603624, 'precision': 0.7456352102397126, 'recall': 0.7267454585248413, 'pr_auc': 0.8201976957602618, 'roc_auc': 0.8531192318489904, 'accuracy': 0.5356881596823074, 'threshold': 0.5999999999999999}
#=44 {'f1': 0.7350924918389554, 'f1_th05': 0.7302603606532776, 'precision': 0.7309565029214455, 'recall': 0.7392755526373386, 'pr_auc': 0.8183146510206885, 'roc_auc': 0.8583840480827416, 'accuracy': 0.5312989863099592, 'threshold': 0.5499999999999999}

#m42 {'f1': 0.7235547695368629, 'f1_th05': 0.7196240430531342, 'precision': 0.7309066547565878, 'recall': 0.716349310571241, 'pr_auc': 0.8018251987226412, 'roc_auc': 0.8472671607959419, 'accuracy': 0.504859441947957, 'threshold': 0.5499999999999999}
#m43 {'f1': 0.7136780717476792, 'f1_th05': 0.7047605287871126, 'precision': 0.6981941900026171, 'recall': 0.7298643029109214, 'pr_auc': 0.7921554606029245, 'roc_auc': 0.8518838914497578, 'accuracy': 0.47622531089978054, 'threshold': 0.5499999999999999}
#m44 {'f1': 0.7129056881893081, 'f1_th05': 0.7038840717424872, 'precision': 0.6868881562262237, 'recall': 0.7409717662508207, 'pr_auc': 0.793177767926983, 'roc_auc': 0.8565165960953717, 'accuracy': 0.4605496917128227, 'threshold': 0.5499999999999999}
