data:
  train: fr
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 4
  best_model_metric: eval_f1
peft:
  enable: True
dataloader:
  train_batch_size: 4
#=42 {'f1': 0.7362065375806788, 'f1_th05': 0.7362065375806788, 'precision': 0.7366666666666667, 'recall': 0.7357469829379941, 'pr_auc': 0.7714117513482799, 'roc_auc': 0.856833033080345, 'accuracy': 0.532634971796938, 'threshold': 0.49999999999999994}
#=43 {'f1': 0.7336846372111876, 'f1_th05': 0.7336846372111876, 'precision': 0.7151323587514816, 'recall': 0.7532251352476071, 'pr_auc': 0.7892240516688256, 'roc_auc': 0.8640173611392812, 'accuracy': 0.5100725221595488, 'threshold': 0.49999999999999994}
#=44 {'f1': 0.7331786542923434, 'f1_th05': 0.7235708692247454, 'precision': 0.7433704020530368, 'recall': 0.7232625884311278, 'pr_auc': 0.8023426171454885, 'roc_auc': 0.851149846378236, 'accuracy': 0.5108783239323127, 'threshold': 0.5499999999999999}

#m42 {'f1': 0.7624620719549199, 'f1_th05': 0.7522159548751006, 'precision': 0.7955676164631389, 'recall': 0.7320016645859343, 'pr_auc': 0.8326819146065922, 'roc_auc': 0.8581048082555134, 'accuracy': 0.5640612409347301, 'threshold': 0.5999999999999999}
#m43 {'f1': 0.7561974563483508, 'f1_th05': 0.7499039569727237, 'precision': 0.7844364937388193, 'recall': 0.7299209321681231, 'pr_auc': 0.8397290791905903, 'roc_auc': 0.8565403696547413, 'accuracy': 0.5656728444802579, 'threshold': 0.5999999999999999}
#m44 {'f1': 0.7576441617073673, 'f1_th05': 0.7456378441256301, 'precision': 0.7473684210526316, 'recall': 0.7682064086558469, 'pr_auc': 0.8321561431143699, 'roc_auc': 0.8732024985771024, 'accuracy': 0.5431103948428686, 'threshold': 0.5499999999999999}
