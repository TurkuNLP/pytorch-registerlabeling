data:
  train: en-fi-sv-tr
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 8
peft:
  enable: True
dataloader:
  train_batch_size: 1
  balancing_sampler: True
# 42 {'f1': 0.7588290407082354, 'f1_th05': 0.7519057883392041, 'precision': 0.7673537259754825, 'recall': 0.7504916792738275, 'pr_auc': 0.8379700841927298, 'roc_auc': 0.8658972568422844, 'accuracy': 0.5598075818495117, 'threshold': 0.5499999999999999}
# 43 {'f1': 0.7531052933307855, 'f1_th05': 0.7481269437376308, 'precision': 0.7615753265826699, 'recall': 0.7448215905654672, 'pr_auc': 0.8285199741227137, 'roc_auc': 0.862823980921005, 'accuracy': 0.5629666858127513, 'threshold': 0.5499999999999999}
# 44 {'f1': 0.7624579639254051, 'f1_th05': 0.7557611762438007, 'precision': 0.7706748039707985, 'recall': 0.7544144893560706, 'pr_auc': 0.8372854302496563, 'roc_auc': 0.8679812234754357, 'accuracy': 0.5626794945433659, 'threshold': 0.5499999999999999}

#z42 {'f1': 0.7114822546972861, 'f1_th05': 0.7114822546972861, 'precision': 0.7138667783829075, 'recall': 0.7091136079900124, 'pr_auc': 0.7836659570482986, 'roc_auc': 0.8426254225401812, 'accuracy': 0.44802578565672846, 'threshold': 0.49999999999999994}
