data:
  train: fi
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 8
  best_model_metric: eval_f1
peft:
  enable: True
dataloader:
  train_batch_size: 1
  test_batch_size: 64
  train_batch_size: 64
#=42 {'f1': 0.794572591587517, 'f1_th05': 0.7873689659635046, 'precision': 0.7943570265870863, 'recall': 0.7947882736156352, 'pr_auc': 0.864586000447274, 'roc_auc': 0.8898279073454392, 'accuracy': 0.6899116689911668, 'threshold': 0.5999999999999999}
#=43 {'f1': 0.791522371519601, 'f1_th05': 0.782564493582412, 'precision': 0.8082036775106082, 'recall': 0.7755157437567861, 'pr_auc': 0.8745635488205998, 'roc_auc': 0.8809901890611205, 'accuracy': 0.6838679683867969, 'threshold': 0.5999999999999999}
#=44 {'f1': 0.796092796092796, 'f1_th05': 0.7820448877805486, 'precision': 0.7957689178193653, 'recall': 0.7964169381107492, 'pr_auc': 0.8720081191290499, 'roc_auc': 0.8906921487583154, 'accuracy': 0.6889818688981869, 'threshold': 0.5999999999999999}


#m42 {'f1': 0.7944809461235217, 'f1_th05': 0.7880380380380382, 'precision': 0.7699949057564952, 'recall': 0.8205754614549403, 'pr_auc': 0.879884028185579, 'roc_auc': 0.9012741354708372, 'accuracy': 0.6638772663877266, 'threshold': 0.5499999999999999}