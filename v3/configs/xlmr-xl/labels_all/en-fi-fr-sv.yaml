data:
  train: en-fi-fr-sv
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 4
peft:
  enable: True
dataloader:
  train_batch_size: 4
  balancing_sampler: True
#=42 {'f1': 0.777934160741377, 'f1_th05': 0.7705663784421989, 'precision': 0.7765289738724274, 'recall': 0.779344442409815, 'pr_auc': 0.8354767394119512, 'roc_auc': 0.8803650888776685, 'accuracy': 0.6002666292450183, 'threshold': 0.5499999999999999}
#=41 {'f1': 0.7753468223940341, 'f1_th05': 0.773025048169557, 'precision': 0.776610157079565, 'recall': 0.7740875912408759, 'pr_auc': 0.8181143044877458, 'roc_auc': 0.8777689400412346, 'accuracy': 0.6010384507437553, 'threshold': 0.5499999999999999}
#=40 {'f1': 0.77736138785807, 'f1_th05': 0.7720818123067786, 'precision': 0.7780583305887949, 'recall': 0.7766656925774401, 'pr_auc': 0.8237965246241973, 'roc_auc': 0.8791133913386405, 'accuracy': 0.6037047431939377, 'threshold': 0.5499999999999999}

# 101 {'f1': 0.7775136848170556, 'f1_th05': 0.771265694159792, 'precision': 0.7670444452339503, 'recall': 0.7882726642082588, 'pr_auc': 0.8333106824073754, 'roc_auc': 0.8841685900705701, 'accuracy': 0.5992141453831041, 'threshold': 0.5499999999999999}
# 40 zero-shot small {'f1': 0.6380047505938242, 'f1_th05': 0.634925487199083, 'precision': 0.6839246307927347, 'recall': 0.5978631844487312, 'pr_auc': 0.6538331804714619, 'roc_auc': 0.785327641087537, 'accuracy': 0.4140339208513469, 'threshold': 0.5499999999999999}
