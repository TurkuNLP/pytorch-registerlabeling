data:
  train: tr
  labels: upper
model:
  name: facebook/xlm-roberta-xl
trainer:
  learning_rate: 1e-4
  gradient_accumulation_steps: 4
peft:
  enable: True
dataloader:
  train_batch_size: 2
#=42 {'f1': 0.7506589351607802, 'f1_th05': 0.745697896749522, 'precision': 0.7730727470141151, 'recall': 0.7295081967213115, 'pr_auc': 0.8201819211241052, 'roc_auc': 0.8503760025984103, 'accuracy': 0.6528384279475983, 'threshold': 0.5499999999999999}
#=43 {'f1': 0.7590422822210902, 'f1_th05': 0.7463252726410621, 'precision': 0.7548125633232016, 'recall': 0.7633196721311475, 'pr_auc': 0.8221492963425144, 'roc_auc': 0.8650115146566579, 'accuracy': 0.6626637554585153, 'threshold': 0.5499999999999999}
#=44 {'f1': 0.7618577075098815, 'f1_th05': 0.7618577075098815, 'precision': 0.7356870229007634, 'recall': 0.7899590163934426, 'pr_auc': 0.821799056426375, 'roc_auc': 0.8759233717080037, 'accuracy': 0.6473799126637555, 'threshold': 0.49999999999999994}
